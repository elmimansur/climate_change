{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CEEQJOhDfDS",
        "outputId": "85dbf7ab-f756-4b5f-8418-3c68a9f4d0e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/232.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8F5ht8cEQo_P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "from nltk.corpus import stopwords\n",
        "from pprint import pprint\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure nltk stopwords are downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Set up stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBLIMDxIICq8",
        "outputId": "843a4382-a55e-418a-f6c6-9438087d9f85"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_txt_to_paragraphs(file_path):\n",
        "    \"\"\"\n",
        "    Read a text file and split it into paragraphs based on empty lines.\n",
        "\n",
        "    :param file_path: Path to the text file.\n",
        "    :return: List of paragraphs, where each paragraph is a string.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Split the content into paragraphs based on empty lines\n",
        "    paragraphs = content.split('\\n\\n')\n",
        "\n",
        "    # Remove any leading/trailing whitespace from each paragraph\n",
        "    paragraphs = [paragraph.strip() for paragraph in paragraphs if paragraph.strip()]\n",
        "\n",
        "    return paragraphs\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/IPCC_AR6_SYR_SPM.txt'\n",
        "paragraphs_list = read_txt_to_paragraphs(file_path)\n",
        "\n",
        "list_policy= paragraphs_list[4:]\n",
        "combined_policy = '\\n\\n'.join(list_policy)"
      ],
      "metadata": {
        "id": "EJVPSU6zE_Y1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text by removing punctuation, stopwords, and performing tokenization.\n",
        "    \"\"\"\n",
        "    text = re.sub('\\s+', ' ', text)  # Remove newlines\n",
        "    text = re.sub(\"\\'\", \"\", text)    # Remove single quotes\n",
        "    text = gensim.utils.simple_preprocess(str(text), deacc=True)  # Tokenization and lowercasing\n",
        "    text = [word for word in text if word not in stop_words]  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "\n",
        "# Function to prepare data for LDA\n",
        "def prepare_data(data):\n",
        "    \"\"\"\n",
        "    Prepare data for LDA model.\n",
        "    \"\"\"\n",
        "    # Preprocess text\n",
        "    data_processed = list(map(preprocess_text, data))\n",
        "\n",
        "    # Create Dictionary\n",
        "    id2word = corpora.Dictionary(data_processed)\n",
        "\n",
        "    # Create Corpus: Term Document Frequency\n",
        "    corpus = [id2word.doc2bow(text) for text in data_processed]\n",
        "\n",
        "    return corpus, id2word\n",
        "\n",
        "# Function to build LDA model\n",
        "def build_lda_model(corpus, id2word, num_topics):\n",
        "    \"\"\"\n",
        "    Build LDA model.\n",
        "    \"\"\"\n",
        "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                                id2word=id2word,\n",
        "                                                num_topics=num_topics,\n",
        "                                                random_state=100,\n",
        "                                                update_every=1,\n",
        "                                                chunksize=10,\n",
        "                                                passes=10,\n",
        "                                                alpha='auto',\n",
        "                                                per_word_topics=True)\n",
        "    return lda_model\n",
        "\n",
        "# Function to compute coherence score\n",
        "def compute_coherence_score(lda_model, texts, id2word):\n",
        "    \"\"\"\n",
        "    Compute coherence score of LDA model.\n",
        "    \"\"\"\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
        "    coherence_lda = coherence_model_lda.get_coherence()\n",
        "    return coherence_lda\n",
        "\n",
        "def main():\n",
        "    data = cleaned_policy\n",
        "\n",
        "    # Prepare data\n",
        "    corpus, id2word = prepare_data(data)\n",
        "\n",
        "    # Build LDA model\n",
        "    lda_model = build_lda_model(corpus, id2word, num_topics=2)\n",
        "\n",
        "    # Print topics\n",
        "    pprint(lda_model.print_topics())\n",
        "\n",
        "    # Compute coherence score\n",
        "    coherence_score = compute_coherence_score(lda_model, list(map(preprocess_text, data)), id2word)\n",
        "    print('\\nCoherence Score: ', coherence_score)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP52HCMr1BB9",
        "outputId": "dd210880-78e6-4190-a2db-8f649eac9ab2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n",
            "WARNING:gensim.models.ldamodel:updated prior is not positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.020*\"high\" + 0.017*\"climate\" + 0.017*\"confidence\" + 0.012*\"adaptation\" + '\n",
            "  '0.011*\"global\" + 0.010*\"risks\" + 0.009*\"change\" + 0.008*\"financial\" + '\n",
            "  '0.007*\"impacts\" + 0.007*\"regions\"'),\n",
            " (1,\n",
            "  '0.020*\"confidence\" + 0.019*\"emissions\" + 0.018*\"high\" + 0.014*\"mitigation\" '\n",
            "  '+ 0.014*\"climate\" + 0.011*\"development\" + 0.009*\"adaptation\" + '\n",
            "  '0.009*\"global\" + 0.008*\"co\" + 0.008*\"warming\"')]\n",
            "\n",
            "Coherence Score:  0.36008899318979337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords(text, num_keywords=10):\n",
        "    words = word_tokenize(text.lower())\n",
        "    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "    word_counts = Counter(filtered_words)\n",
        "    return word_counts.most_common(num_keywords)\n",
        "\n",
        "keywords = extract_keywords(combined_policy)\n",
        "print(keywords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHgXKfpF1N8z",
        "outputId": "c0d804ac-28b2-4220-ee4f-fb3b7d194567"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('high', 267), ('confidence', 256), ('emissions', 190), ('climate', 188), ('global', 177), ('adaptation', 142), ('warming', 137), ('mitigation', 106), ('change', 97), ('figure', 96)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_for_lda(text):\n",
        "    words = [word for word in word_tokenize(text.lower()) if word.isalnum() and word not in stop_words]\n",
        "    dictionary = corpora.Dictionary([words])\n",
        "    corpus = [dictionary.doc2bow(words)]\n",
        "    return corpus, dictionary\n",
        "\n",
        "corpus, dictionary = prepare_data_for_lda(combined_policy)\n",
        "lda_model = LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15)\n",
        "topics = lda_model.print_topics(num_words=4)\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyCXJx1AJ_Lq",
        "outputId": "e5348875-c44f-4013-f840-5f5344cd7f48"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.020*\"high\" + 0.019*\"confidence\" + 0.014*\"emissions\" + 0.014*\"climate\"')\n",
            "(1, '0.001*\"high\" + 0.001*\"confidence\" + 0.001*\"climate\" + 0.001*\"global\"')\n",
            "(2, '0.001*\"emissions\" + 0.001*\"confidence\" + 0.001*\"high\" + 0.001*\"global\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qx9qZ1LsLaUU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}